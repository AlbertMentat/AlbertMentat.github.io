---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I'm a junior student from [SJTU Paris Elite Institute of Technology](https://speit.sjtu.edu.cn/), [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/). Currently I am a research assistant at [Center for Brain-like Computing and Machine Intelligence (BCMI)](https://bcmi.sjtu.edu.cn/), under the supervision of [Weilong Zheng](https://weilongzheng.github.io/). My reasearch interests in affective brain-computer interfaces. Now I focus on Emotion Recognition in a natural state and Large Brain Model. If you have any interest in it, please feel free to discuss with me.

Interests
======
Affective Computing, Brain-Computer Interactions, Artificial Intelligence, Machine Learning

News
======
- **2024.12** 1 paper is accepted by ICASSP!

Publications
======
- * **Jun-Yu Pan**, Hao-Long Yin, Wei-Long Zheng (2025). Double Domain Converter Transformer For Improving EEG-Based Emotion Recognition from Video to Game Scenarios. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).

Projects
======
### Cross-Scenario Emotion Recognition 
*Machine Learning and Affective Intelligence* 
  
June 2023 -- Present
- Traditional emotion recognition approaches usually utilize videos as stimuli. However, watching videos lacks interaction. This project adopts games as emotion elicitation stimuli to explore the relationship of emotion recognition in different scenarios (game and video scenarios).
- We also propose Double Domain Converter Transformer (DDCT) which achieves a remarkable prediction accuracy of cross-scenario emotion recognition.
- One paper is accepted by ICASSP.
- Explore the combination of screen recordings or videos and EEG in Multimodal Large Brain Model.

### Explore the use of Contrastive Learning in Emotion Recognition 
*Machine Learning and Affective Intelligence* 

July 2024 -- Present
- The study follows the way of SimCLR.
- Compared with traditional domain adaptation methods, self-supervised method based on contrastive pre-training show great potential in cross-scenario emotion recognition.
- Compared with MAE pre-training, contrastive pre-training achieves better performance in cross-scenario emotion recognition and has similar performance in traditional video-stimuli emotion recognition.

Internships
======
- **2023.06-Now** Research Assistant in [BCMI](https://bcmi.sjtu.edu.cn/). Advisor: [Weilong Zheng](https://weilongzheng.github.io/).
